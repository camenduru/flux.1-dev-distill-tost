{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!pip install torchsde einops diffusers transformers accelerate peft timm kornia aiohttp\n",
    "!apt install -qqy\n",
    "\n",
    "!git clone https://github.com/comfyanonymous/ComfyUI /content/ComfyUI\n",
    "!git clone https://github.com/ltdrdata/ComfyUI-Manager /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
    "\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/consolidated_s6700.safetensors -d /content/ComfyUI/models/unet -o consolidated_s6700.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_g.safetensors -d /content/ComfyUI/models/clip -o clip_g.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/t5xxl_fp16.safetensors -d /content/ComfyUI/models/clip -o t5xxl_fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/Long-ViT-L-14-BEST-GmP-smooth-ft.safetensors -d /content/ComfyUI/models/clip -o Long-ViT-L-14-BEST-GmP-smooth-ft.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft -d /content/ComfyUI/models/vae -o ae.sft\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/detailed_v2_flux_ntc.safetensors -d /content/ComfyUI/models/loras -o detailed_v2_flux_ntc.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/openflux1-v0.1.0-fast-lora.safetensors -d /content/ComfyUI/models/loras -o openflux1-v0.1.0-fast-lora.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/xlabs_flux_realism_lora_comfui.safetensors -d /content/ComfyUI/models/loras -o xlabs_flux_realism_lora_comfui.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/FLUX.1-Turbo-Alpha.safetensors -d /content/ComfyUI/models/loras -o FLUX.1-Turbo-Alpha.safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/ComfyUI\n",
    "\n",
    "import os, shutil, json, requests, random, time\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from nodes import NODE_CLASS_MAPPINGS, load_custom_node\n",
    "from comfy_extras import nodes_flux, nodes_model_advanced, nodes_custom_sampler, nodes_sd3\n",
    "\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/ComfyUI-Adaptive-Guidance\")\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/ComfyUI-Detail-Daemon\")\n",
    "\n",
    "UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
    "TripleCLIPLoader = nodes_sd3.NODE_CLASS_MAPPINGS[\"TripleCLIPLoader\"]()\n",
    "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
    "CLIPVisionLoader = NODE_CLASS_MAPPINGS[\"CLIPVisionLoader\"]()\n",
    "LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
    "StyleModelLoader =  NODE_CLASS_MAPPINGS[\"StyleModelLoader\"]()\n",
    "LoraLoader = NODE_CLASS_MAPPINGS[\"LoraLoader\"]()\n",
    "\n",
    "ModelSamplingFlux = nodes_model_advanced.NODE_CLASS_MAPPINGS[\"ModelSamplingFlux\"]()\n",
    "CLIPTextEncode = NODE_CLASS_MAPPINGS[\"CLIPTextEncode\"]()\n",
    "RandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\n",
    "AdaptiveGuidance = NODE_CLASS_MAPPINGS[\"AdaptiveGuidance\"]()\n",
    "KSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\n",
    "BasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\n",
    "DetailDaemonSamplerNode = NODE_CLASS_MAPPINGS[\"DetailDaemonSamplerNode\"]()\n",
    "SamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\n",
    "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
    "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    unet = UNETLoader.load_unet(\"consolidated_s6700.safetensors\", \"fp8_e4m3fn\")[0]\n",
    "    clip = TripleCLIPLoader.load_clip(\"google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"Long-ViT-L-14-BEST-GmP-smooth-ft.safetensors\", \"clip_g.safetensors\")[0]\n",
    "    unet1, clip1 = LoraLoader.load_lora(unet, clip, \"flux/FLUX.1-Turbo-Alpha.safetensors\", 1.00, 1.00)\n",
    "    unet2, clip2 = LoraLoader.load_lora(unet1, clip1, \"flux/openflux1-v0.1.0-fast-lora.safetensors\", 0.33, 0.33)\n",
    "    unet3, clip3 = LoraLoader.load_lora(unet2, clip2, \"flux/xlabs_flux_realism_lora_comfui.safetensors\", 0.70, 0.70)\n",
    "    unet4, clip4 = LoraLoader.load_lora(unet3, clip3, \"flux/detailed_v2_flux_ntc.safetensors\", 0.70, 0.70)\n",
    "    vae = VAELoader.load_vae(\"ae.sft\")[0]\n",
    "\n",
    "def download_file(url, save_dir, file_name):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_suffix = os.path.splitext(urlsplit(url).path)[1]\n",
    "    file_name_with_suffix = file_name + file_suffix\n",
    "    file_path = os.path.join(save_dir, file_name_with_suffix)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    return file_path\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate(input):\n",
    "    values = input[\"input\"]\n",
    "\n",
    "    positive_prompt = values['positive_prompt']\n",
    "    negative_prompt = values['negative_prompt']\n",
    "    seed = values['seed']\n",
    "    steps = values['steps']\n",
    "    cfg = values['cfg']\n",
    "    sampler_name = values['sampler_name']\n",
    "    scheduler = values['scheduler']\n",
    "    max_shift = values['max_shift']\n",
    "    base_shift = values['base_shift']\n",
    "    width = values['width']\n",
    "    height = values['height']\n",
    "\n",
    "    if seed == 0:\n",
    "        random.seed(int(time.time()))\n",
    "        seed = random.randint(0, 18446744073709551615)\n",
    "    print(seed)\n",
    "\n",
    "    positive = CLIPTextEncode.encode(clip4, positive_prompt)[0]\n",
    "    negative = CLIPTextEncode.encode(clip4, negative_prompt)[0]\n",
    "    unet_flux = ModelSamplingFlux.patch(unet4, max_shift, base_shift, width, height)[0]\n",
    "    noise = RandomNoise.get_noise(seed)[0]\n",
    "    guider = AdaptiveGuidance.get_guider(unet_flux, positive, negative, 1.0, cfg, uncond_zero_scale=0.0, cfg_start_pct=0.0)[0]\n",
    "    sampler = KSamplerSelect.get_sampler(sampler_name)[0]\n",
    "    sigmas = BasicScheduler.get_sigmas(unet_flux, scheduler, steps, 1.0)[0]\n",
    "    latent_image = EmptyLatentImage.generate(width, height)[0]\n",
    "    sampler = DetailDaemonSamplerNode.go(sampler=sampler, detail_amount=0.2, start=0.2, end=0.9, bias=1.0, exponent=1.0, start_offset=0.0, end_offset=0.0, fade=0.0, smooth=False, cfg_scale_override=0.0)[0]\n",
    "    samples, _ = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent_image)\n",
    "    decoded = VAEDecode.decode(vae, samples)[0].detach()\n",
    "    Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(f\"/content/flux.1-dev-distill-{seed}-tost.png\")\n",
    "\n",
    "    result = f\"/content/flux.1-dev-distill-{seed}-tost.png\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = { \n",
    "        \"input\": {\n",
    "        \"positive_prompt\": \"This photograph captures a young Asian woman with fair skin, sitting on a large rock beside a sandy beach. She has straight black hair pulled back and is wearing a colorful one-piece swimsuit in blue, orange, and white with a frilly detail at the hips. Her swimsuit accentuates her medium-sized breasts and slim physique. She is smiling and looking up at the camera. The background features lush green foliage and a sandy beach with scattered rocks. She is wearing white Adidas sneakers.\",\n",
    "        \"negative_prompt\": \"(cartoon:0.5)\",\n",
    "        \"seed\": 1,\n",
    "        \"steps\": 8,\n",
    "        \"cfg\": 3.5,\n",
    "        \"sampler_name\": \"euler\",\n",
    "        \"scheduler\": \"normal\",\n",
    "        \"max_shift\": 1.15,\n",
    "        \"base_shift\": 0.50,\n",
    "        \"width\": 1344,\n",
    "        \"height\": 768\n",
    "    }\n",
    "}\n",
    "image = generate(input)\n",
    "Image.open(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComfyUI-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
